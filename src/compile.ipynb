{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4287413e-0a91-45d2-b00e-7569bfbc48b3",
   "metadata": {},
   "source": [
    "# Compile data\n",
    "\n",
    "The purpose of this notebook is to:\n",
    "\n",
    "1. Combine Tully Runners speed ratings `xlsx` files\n",
    "2. Fix small Tully Runner's data inaccuracies\n",
    "3. Convert time to seconds and clean invalid times\n",
    "4. Merge location data to speed ratings\n",
    "5. Merge weather data to speed ratings\n",
    "6. Merge distance data to speed ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023c7019-c0d5-4a25-89ca-24f99aae7e84",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ff718f9-fbca-4fc9-b5be-391244bf201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08768c29-f171-41fb-8b49-52b1ff8b38e3",
   "metadata": {},
   "source": [
    "## Combine Tully Runners speed ratings `xlsx` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "984ad7a3-f810-442a-986d-b6822c265b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014, 2015, 2016, 2017, 2018, 2019, Finished! (387279, 12)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for year in range(2014, 2020):\n",
    "    print(year, end=\", \")\n",
    "    \n",
    "    girls_df = pd.read_excel(f'../data/tully_runners/XCgirls{year}.xlsx')[:-5]\n",
    "    girls_df['Gender'] = 'Female'\n",
    "    boys_df = pd.read_excel(f'../data/tully_runners/XCboys{year}.xlsx')[:-5]\n",
    "    boys_df['Gender'] = 'Male'\n",
    "    \n",
    "    df = pd.concat([df, girls_df, boys_df], axis=0)\n",
    "\n",
    "print(f'Finished! {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc820dc-65f1-4b47-8548-351f678f91b4",
   "metadata": {},
   "source": [
    "## Fix small Tully Runner's data inaccuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c2670e5-f1eb-4bc2-aeee-169469525a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old: (387279, 12), New: (386345, 12), Complete!\n"
     ]
    }
   ],
   "source": [
    "print(f'Old: {df.shape}', end=\", \")\n",
    "\n",
    "df.replace(' ', np.nan, inplace=True)\n",
    "df[\"Class\"].replace('c', 'C', inplace=True)\n",
    "df[\"Section\"].replace('08=', '08-', inplace=True)\n",
    "df[\"Section\"].replace('50-', '05-', inplace=True)\n",
    "\n",
    "non_NA_cols = ['Speed Rating', 'SR', 'Time', 'Grade', 'Place']\n",
    "\n",
    "df = df.dropna(subset=non_NA_cols)\n",
    "df = df[df[non_NA_cols].astype(str).apply(lambda x: x.str.strip().str.len() > 0).all(axis=1)]\n",
    "    \n",
    "print(f'New: {df.shape}, Complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be845073-9fee-49df-9b77-cd4b21795405",
   "metadata": {},
   "source": [
    "## Convert time to seconds and clean invalid times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a96c5b08-a35f-4e09-a035-72d76abe04fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted Time (sec) column! --- Cleaned invalid times!\n"
     ]
    }
   ],
   "source": [
    "def time_to_seconds(t):\n",
    "    if hasattr(t, 'minute') and hasattr(t, 'second'):\n",
    "        if t.hour and t.hour > 1:\n",
    "            return t.hour * 60 + t.minute\n",
    "        return t.hour * 3600 + t.minute * 60 + t.second\n",
    "\n",
    "    if isinstance(t, str):\n",
    "        try:\n",
    "            parts = t.split(':')\n",
    "            if len(parts) != 2:\n",
    "                raise ValueError(\"Expected format 'HH:MM;SS'\")\n",
    "            \n",
    "            minutes = int(parts[0])\n",
    "            seconds = int(parts[1].split(';')[0])\n",
    "            \n",
    "            return minutes * 60 + seconds\n",
    "\n",
    "        except (IndexError, ValueError) as e:\n",
    "            print(f\"Error parsing time string: {t}. Reason: {e}\")\n",
    "            return None\n",
    "            \n",
    "    print(f\"Unrecognized time format: {t}\")\n",
    "    return None\n",
    "\n",
    "if 'Time' in df.columns:\n",
    "    time_col_position = df.columns.get_loc('Time')\n",
    "    df.insert(time_col_position + 1, 'Time (sec)', df['Time'].apply(time_to_seconds))\n",
    "    print(\"Inserted Time (sec) column!\", end=\" --- \")\n",
    "    \n",
    "    df = df[df['Time (sec)'] >= 500].copy()\n",
    "    print(f\"Cleaned invalid times!\")\n",
    "    df.drop('Time', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c146a2e3-5b37-4b04-82f5-db1fc2ae6802",
   "metadata": {},
   "source": [
    "## Merge location data to speed ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6021e4e6-6cdd-464c-9419-a66c480add1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location! ['Name', 'Grade', 'Section', 'Class', 'School', 'Race', 'Date', 'Place', 'Time (sec)', 'Speed Rating', 'SR', 'Gender', 'Race Section', 'Latitude', 'Longitude']\n"
     ]
    }
   ],
   "source": [
    "df_common_sections = df.groupby('Race')['Section'].apply(lambda x: x.mode().iloc[0]).reset_index()\n",
    "df_section_locations = pd.read_csv(\"../data/location.csv\")\n",
    "df_race_section_location = df_common_sections.merge(df_section_locations[['Section', 'Latitude', 'Longitude']], on='Section', how='left')\n",
    "df_race_section_location = df_race_section_location.rename(columns={'Section': 'Race Section'})\n",
    "df = df.merge(df_race_section_location[['Race', 'Race Section', 'Latitude', 'Longitude']], on='Race', how='left')\n",
    "print('Location!', list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8614a6-ec6e-4760-ab07-d2df642f6867",
   "metadata": {},
   "source": [
    "## Merge weather data to speed ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2569d9a5-6747-47bf-84ba-63ab86d594b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather! ['Name', 'Grade', 'Section', 'Class', 'School', 'Race', 'Date', 'Place', 'Time (sec)', 'Speed Rating', 'SR', 'Gender', 'Race Section', 'Latitude', 'Longitude', 'Temperature', 'Cloud Coverage', 'Wind Speed', 'Precipitation', 'Dew Point', 'Humidity', 'Wind Chill', 'Wind Gust', 'Heat Index', 'Visibility']\n"
     ]
    }
   ],
   "source": [
    "weather_df = pd.read_csv(\"../data/weather.csv\")\n",
    "drop_weather_cols = ['Precipitation Coverage', 'Snow', 'Snow Depth']\n",
    "if 'Unnamed: 0' in weather_df.columns: drop_weather_cols.append('Unnamed: 0')\n",
    "if 'WeatherData' in weather_df.columns: drop_weather_cols.append('WeatherData')\n",
    "weather_df.drop(drop_weather_cols, axis=1, inplace=True) # all columns above are unwanted/all null\n",
    "\n",
    "weather_df['Date'] = weather_df['Date'].astype(str).str.strip()\n",
    "df['Date'] = df['Date'].astype(str).str.strip()\n",
    "\n",
    "df = pd.merge(df, weather_df, on=['Date', 'Latitude', 'Longitude'], how='inner')\n",
    "print('Weather!', list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0fa5e2-aa36-4015-ad93-ee69549333e0",
   "metadata": {},
   "source": [
    "## Merge distance data to speed ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3553fad3-5d29-40c3-a562-9835bfad8458",
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile('../data/distance.xlsx')\n",
    "sheet_names = xls.sheet_names\n",
    "\n",
    "distance_data = {}\n",
    "for sheet in sheet_names:\n",
    "    distance_data[sheet] = pd.read_excel(xls, sheet_name=sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9e7a0e2-7a48-4313-b115-098f42c9eca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Year'] = pd.to_datetime(df['Date']).dt.year\n",
    "df = df[(df['Year'] >= 2014) & (df['Year'] <= 2019)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5adc5c-c810-461c-8925-0e591e7c4c29",
   "metadata": {},
   "source": [
    "Sequence match MileSplit race names to Tully Runner's race names. Naming syntax is different per race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8244e314-9627-4e05-929c-a09895071c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014, 2015, 2016, 2017, 2018, 2019, "
     ]
    }
   ],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def remove_keywords(text, keywords=[]):\n",
    "    for keyword in keywords:\n",
    "        text = text.replace(keyword, \"\")\n",
    "    return text.strip()\n",
    "\n",
    "def remove_ending_if_present(s, endings):\n",
    "    for ending in endings:\n",
    "        if s.endswith(ending):\n",
    "            return s[:-len(ending)]\n",
    "    return s\n",
    "\n",
    "def find_closest_match(race_name, year):\n",
    "    kw = [\"-V\", \"-JV\", \"-Chm\", \"Class A\", \"Class B\", \"Class C\", \"Class D\", \"Class\", \"Championship\", \"Champ\", \"Invitational\", \"Invite\", \"Invit\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\"]\n",
    "    race_name = remove_keywords(race_name, kw)\n",
    "    races = df[df['Year'] == year]['Race']   \n",
    "\n",
    "    kw2 = [\"-Class A\", \"-Class B\", \"-Class C\", \"-Class D\", \"-VB\", \"-Lg\", \"-Md\", \"-Sm\", \"-A\", \"-B\", \"-C\", \"-D\", \"-V\", \"-JV\", \"-Chm\", \" A\", \" B\", \" C\", \" D\", \" V\", \" JV\", \" Chm\", \" Class A\", \" Class B\", \" Class C\", \" Class D\", \" Lg\", \" Md\", \" Sm\"]\n",
    "    \n",
    "    max_similarity = 0\n",
    "    matched_race = None\n",
    "\n",
    "    for race in races:\n",
    "        similarity = SequenceMatcher(None, race_name, remove_keywords(race, kw)).ratio()\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            matched_race = remove_ending_if_present(race, kw2)\n",
    "    return matched_race\n",
    "\n",
    "for year in distance_data:\n",
    "    print(year, end=\", \")\n",
    "    for race in distance_data[year][\"Race\"]:\n",
    "        match = find_closest_match(race, 2014)\n",
    "        mask = distance_data[year][\"Race\"] == race\n",
    "        distance_data[year].loc[mask, \"DB-Race\"] = match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f01dc0-8801-4c7e-ba82-993ed49d4358",
   "metadata": {},
   "source": [
    "Fix sequence matching mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0faed2aa-b5ec-48b8-9a05-407176a7f8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_data[\"2019\"][distance_data[\"2019\"] == \"NYSPHSAA Championships 2019\"][\"DB-Race\"] = \"NY States\"\n",
    "distance_data[\"2014\"][distance_data[\"2014\"] == \"Section 7 Championships 2014\"][\"DB-Race\"] = \"Section 7-Class\"\n",
    "distance_data[\"2014\"].loc[distance_data[\"2014\"][\"Race\"] == \"Chittenango Modified Invitational 2014\", \"Year\"] = 3.1\n",
    "distance_data[\"2015\"].loc[distance_data[\"2015\"][\"Race\"] == \"Chittenango Modified Invitational 2015\", \"Year\"] = 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cec3588-d341-4a05-a43f-e1258a51a992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014, 2015, 2016, 2017, 2018, 2019, "
     ]
    }
   ],
   "source": [
    "for year in distance_data:\n",
    "    print(year, end=\", \")\n",
    "    for distance, race in zip(distance_data[year][\"Year\"], distance_data[year][\"DB-Race\"]):\n",
    "        df.loc[(df[\"Race\"].str.startswith(race)) & (df[\"Year\"] == int(year)), \"Distance (mi)\"] = distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c27efac-f248-43a3-8a9f-2407c141ef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[pd.isna(df[\"Distance (mi)\"]), \"Distance (mi)\"] = 3.106\n",
    "df = df[df[\"Distance (mi)\"] != \"?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9e61b6a-8248-42c6-9751-2e507ab2aaa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'Grade', 'Section', 'Class', 'School', 'Race', 'Date', 'Place',\n",
       "       'Time (sec)', 'Speed Rating', 'SR', 'Gender', 'Race Section',\n",
       "       'Latitude', 'Longitude', 'Temperature', 'Cloud Coverage', 'Wind Speed',\n",
       "       'Precipitation', 'Dew Point', 'Humidity', 'Wind Chill', 'Wind Gust',\n",
       "       'Heat Index', 'Visibility', 'Year', 'Distance (mi)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_labeled = df[(df['Time (sec)'] < 990) & (df['Time (sec)'] > 0) & (df['Speed Rating'] < 130) & (df['Speed Rating'] > 95) & (df['Distance (mi)'] > 2.5)]\n",
    "df.loc[df[\"Race\"].isin(mis_labeled[\"Race\"].unique()), \"Distance (mi)\"] = 2.5\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb1cefd9-a33d-466d-bfb6-0d18ec66b2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to compiled.csv!\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"../data/compiled.csv\", index=False)\n",
    "print(\"Saved to compiled.csv!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
